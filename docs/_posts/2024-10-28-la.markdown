---
layout: post
title:  "Linear Algebra"
date:   2024-10-28
categories: daily log
---

### Linear Algebra
- Pavel Grinfeld [LA series on YT](https://www.youtube.com/playlist?list=PLlXfTHzgMRUKXD88IdzS14F4NxAZudSmv)
  - [Lemma](https://www.lem.ma/library)
   - our eye has 100 million sensors in the retina (rod & cone cells) but our ears have only one sensor. Sound enters our ears as a combination(summation) which are then decomposed as a result of which we can hear the individual sound sources.
   - mlk + bach = mlk - bach (mlk - martin luther king). The intuition is that any sound signal can be decomposed as a set of sine waves, so -bach is just a phase shifted sine wave. So addition or subtraction sounds the same.

- Sheldon Axler [Linear Algebra Done Right](https://linear.axler.net/)
  - [video playlist](https://www.youtube.com/playlist?list=PLGAnmvB9m7zOBVCZBUUmSinFV0wEir2Vw) for the book
  - Complex numbers
    - Some polynomials with real coefficients have no real zeros. eg. the equation $x^2 + 1 = 0$ has no real solutions. Thus we invent a solution called i with the property that $i^2 =-1$
    - The symbol i was first used to denote $\sqrt{âˆ’1}$ by Leonhard Euler in 1777
    - were invented so that we can take square root of negative numbers
  
- [Deep Learning book](https://www.deeplearningbook.org/)
  - linear algebra is a form of continuous rather than discrete mathematics. A good understanding of linear algebra is essential for understanding and working with many machine learning algorithms, especially deep learning algorithms.
  - Scalars, Vectors, Matrices, Tensors
  - Multiplying Matrices and Vectors
  - Identity and Inverse Matrices
  - Linear Dependence and Span
  - Norms
  - Special kinds of Matrices and Vectors
    - Diagonal
    - Symmetric
    - Orthogonal
    - Unit vector
  - Eigen decomposition
  - Singular Value Decomposition (SVD)
  - The Moore-Penrose Pseudoinverse
  - The Trace operator
  - The Determinant
  - Example: Principal Components Analysis (PCA)
    - One simple machine learning algorithm, PCA, can be derived using only knowledge of basic linear algebra.
   
- [Linear Algebra by Jim Hefferon](https://hefferon.net/linearalgebra/)
  - [video playlist](https://www.youtube.com/playlist?list=PLwF3A0R8OzMoMlE1-SaEh8h9VqUlO-r52)
  - [solution manual](https://jheffero.w3.uvm.edu/linearalgebra/jhanswer.pdf)
- [Linear Algebra lecture notes of William Chen](https://www.williamchen-mathematics.info/lnlafolder/lnla.html)

### [Single Variable Calculus](https://ocw.mit.edu/courses/18-01sc-single-variable-calculus-fall-2010/)
  - [purpose of recitation](https://www.youtube.com/watch?v=2y4tCiWbVRI&t=5s)
    
### [Multivariable Calculus](https://www.youtube.com/watch?v=PxCxlsl_YwY&t=65s)      
  - [Syllabus](https://ocw.mit.edu/courses/18-02sc-multivariable-calculus-fall-2010/pages/syllabus/)

### [Matrix Calculus for ML and beyond](https://www.youtube.com/playlist?list=PLUl4u3cNGP62EaLLH92E_VCN4izBKK6OE)
  - [So you think you know how to take derivatives](https://www.youtube.com/watch?v=-l7JHalBubw)
  - [github page](https://github.com/mitmath/matrixcalc)
  - [instructor insights](https://ocw.mit.edu/courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/pages/instructor-insights/)
